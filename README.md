# ğŸ“š Legal RAG Assistant (FastAPI + Streamlit + Pinecone + Groq)

A Retrieval-Augmented Generation (RAG) based legal assistant that allows you to:

âœ… Upload documents (PDF/TXT)  
âœ… Store & embed them into Pinecone  
âœ… Ask legal questions using natural language  
âœ… Get responses powered by Groq LLM + document context  

---

## ğŸš€ Tech Stack

| Layer | Tech |
|-------|------|
| Backend API | FastAPI |
| Frontend UI | Streamlit |
| Vector DB | Pinecone |
| Embeddings | SentenceTransformer (`all-MiniLM-L6-v2`) |
| LLM Inference | Groq API |
| File Parsing | pypdf / txt |
| Environment | Python 3.9+ |

---

## ğŸ”§ 1. Setup & Installation

### 1ï¸âƒ£ Clone repo & enter project

git clone https://github.com/uzairabbasi989/RAG

cd project

2ï¸âƒ£ Create Virtual Environment

python -m venv venv

source venv/bin/activate       # Mac/Linux

venv\Scripts\activate          # Windows

3ï¸âƒ£ Install dependencies

pip install -r requirements.txt

4ï¸âƒ£ Create .env file

PINECONE_API_KEY=your_key_here

GROQ_API_KEY=your_key_here

INDEX_NAME=legal-index

ğŸ—‚ï¸ 2. Run Backend (FastAPI)

uvicorn main:app --reload

Backend will run at:

â¡ï¸ http://127.0.0.1:8000

API Docs available at:

â¡ï¸ http://127.0.0.1:8000/docs

ğŸ’» 3. Run Frontend (Streamlit)

streamlit run frontend.py

Frontend will open in browser automatically.

Used for:

Uploading documents

Asking questions

Chat-like Q/A interface

ğŸ“¤ 4. Upload Documents

You can upload .pdf or .txt files directly from the Streamlit UI.

The system will:

âœ… Read content
âœ… Chunk text
âœ… Generate embeddings
âœ… Store vectors in Pinecone

No manual ingestion script is required.

ğŸ’¬ 5. Ask Questions

You can query documents in two ways:

âœ… Using Streamlit UI (recommended)
Open the web UI and chat.

âœ… Using API directly:

curl "http://127.0.0.1:8000/ask?query=What is termination clause?"

ğŸ“ Project Structure

project/
â”‚ backend.py               # FastAPI backend
â”‚ frontend.py           # Streamlit UI
â”‚ requirements.txt
â”‚ README.md
| .gitignore
â”‚ .env
â”‚
â””â”€â”€ documents/          # (optional) local storage

ğŸ”„ Workflow Summary
markdown

1. Upload documents via Streamlit
2. System embeds and stores chunks in Pinecone
3. User enters question
4. System retrieves relevant chunks
5. Sends context + question to Groq LLM
6. Returns answer with cited sources
7. 
âœ… TODO (future improvements)
 Doc duplicate detection via hashing

 Add support for DOCX + HTML

 "Delete document" API

 PDF OCR for scanned files

 Streamed responses

ğŸ›  Troubleshooting
Issue	Fix
Backend not responding	Make sure FastAPI is running
Pinecone errors	Check .env API key & index name
No answer returned	Ensure some docs are uploaded first
CORS blocked	Use --reload or enable CORS in FastAPI

ğŸ“œ License
MIT â€” feel free to use, modify, distribute.

âœ¨ Author
Made by uzair using Groq + Pinecone + FastAPI + Streamlit
